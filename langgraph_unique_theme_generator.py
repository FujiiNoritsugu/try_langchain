"""
LangGraphã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²ã•ã‚ŒãŸãƒ†ãƒ¼ãƒåã¨é¡ä¼¼ã—ãªã„ãƒ†ãƒ¼ãƒåã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
Anthropic Claude APIã‚’ä½¿ç”¨
"""
import sqlite3
import uuid
from typing import TypedDict, List, Annotated
import operator
import os
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain_voyageai import VoyageAIEmbeddings
from langgraph.graph import StateGraph, END
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
def init_database(db_path: str = "themes.db"):
    """SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS themes (
            id TEXT PRIMARY KEY,
            theme_name TEXT NOT NULL
        )
    """)

    conn.commit()
    conn.close()


def add_theme_to_db(theme_name: str, db_path: str = "themes.db"):
    """ãƒ†ãƒ¼ãƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    theme_id = str(uuid.uuid4())
    cursor.execute("INSERT INTO themes (id, theme_name) VALUES (?, ?)", (theme_id, theme_name))

    conn.commit()
    conn.close()
    return theme_id


def get_all_themes(db_path: str = "themes.db") -> List[str]:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ã¦ã®ãƒ†ãƒ¼ãƒåã‚’å–å¾—"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("SELECT theme_name FROM themes")
    themes = [row[0] for row in cursor.fetchall()]

    conn.close()
    return themes


# LangGraphã®çŠ¶æ…‹å®šç¾©
class ThemeGenerationState(TypedDict):
    """ãƒ†ãƒ¼ãƒç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã®çŠ¶æ…‹"""
    existing_themes: List[str]  # æ—¢å­˜ã®ãƒ†ãƒ¼ãƒä¸€è¦§
    candidate_theme: str  # ç”Ÿæˆå€™è£œã®ãƒ†ãƒ¼ãƒ
    is_unique: bool  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‹ã©ã†ã‹
    attempt_count: int  # è©¦è¡Œå›æ•°
    max_attempts: int  # æœ€å¤§è©¦è¡Œå›æ•°
    similarity_threshold: float  # é¡ä¼¼åº¦ã®é–¾å€¤
    max_similarity: float  # æ—¢å­˜ãƒ†ãƒ¼ãƒã¨ã®æœ€å¤§é¡ä¼¼åº¦
    db_path: str  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
    category: str  # ãƒ†ãƒ¼ãƒã®ã‚«ãƒ†ã‚´ãƒªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šï¼‰


# ãƒãƒ¼ãƒ‰é–¢æ•°ã®å®šç¾©
def fetch_existing_themes(state: ThemeGenerationState) -> ThemeGenerationState:
    """æ—¢å­˜ã®ãƒ†ãƒ¼ãƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—"""
    themes = get_all_themes(state["db_path"])
    state["existing_themes"] = themes
    print(f"ğŸ“š æ—¢å­˜ãƒ†ãƒ¼ãƒæ•°: {len(themes)}")
    return state


def generate_theme(state: ThemeGenerationState) -> ThemeGenerationState:
    """LLMã‚’ä½¿ã£ã¦æ–°ã—ã„ãƒ†ãƒ¼ãƒã‚’ç”Ÿæˆ"""
    state["attempt_count"] += 1
    print(f"\nğŸ² ãƒ†ãƒ¼ãƒç”Ÿæˆè©¦è¡Œ: {state['attempt_count']}/{state['max_attempts']}")

    llm = ChatAnthropic(model="claude-3-haiku-20240307", temperature=0.9)

    existing_themes_str = "\n".join([f"- {theme}" for theme in state["existing_themes"]])

    prompt = f"""ä»¥ä¸‹ã®æ—¢å­˜ã®ãƒ†ãƒ¼ãƒã¨ã¯ç•°ãªã‚‹ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§å‰µé€ çš„ãªãƒ†ãƒ¼ãƒã‚’1ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚«ãƒ†ã‚´ãƒª: {state['category']}

æ—¢å­˜ã®ãƒ†ãƒ¼ãƒ:
{existing_themes_str if existing_themes_str else "ï¼ˆã¾ã ãƒ†ãƒ¼ãƒã¯ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰"}

è¦ä»¶:
- æ—¢å­˜ã®ãƒ†ãƒ¼ãƒã¨å†…å®¹ã‚„è¨€è‘‰é£ã„ãŒå¤§ããç•°ãªã‚‹ã“ã¨
- ç°¡æ½”ã§é­…åŠ›çš„ãªãƒ†ãƒ¼ãƒåã§ã‚ã‚‹ã“ã¨
- ãƒ†ãƒ¼ãƒåã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""

    response = llm.invoke(prompt)
    candidate = response.content.strip()
    state["candidate_theme"] = candidate
    print(f"ğŸ’¡ ç”Ÿæˆã•ã‚ŒãŸãƒ†ãƒ¼ãƒ: {candidate}")

    return state


def check_similarity(state: ThemeGenerationState) -> ThemeGenerationState:
    """æ—¢å­˜ãƒ†ãƒ¼ãƒã¨ã®é¡ä¼¼åº¦ã‚’ãƒã‚§ãƒƒã‚¯"""
    if not state["existing_themes"]:
        # æ—¢å­˜ãƒ†ãƒ¼ãƒãŒãªã„å ´åˆã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯
        state["is_unique"] = True
        state["max_similarity"] = 0.0
        print("âœ… æ—¢å­˜ãƒ†ãƒ¼ãƒãŒãªã„ãŸã‚ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ã¨åˆ¤å®š")
        return state

    embeddings = VoyageAIEmbeddings(model="voyage-3-lite")

    # å€™è£œãƒ†ãƒ¼ãƒã¨æ—¢å­˜ãƒ†ãƒ¼ãƒã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
    candidate_embedding = embeddings.embed_query(state["candidate_theme"])
    existing_embeddings = embeddings.embed_documents(state["existing_themes"])

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
    candidate_vector = np.array(candidate_embedding).reshape(1, -1)
    existing_vectors = np.array(existing_embeddings)

    similarities = cosine_similarity(candidate_vector, existing_vectors)[0]
    max_similarity = float(np.max(similarities))

    state["max_similarity"] = max_similarity
    state["is_unique"] = max_similarity < state["similarity_threshold"]

    print(f"ğŸ“Š æœ€å¤§é¡ä¼¼åº¦: {max_similarity:.4f} (é–¾å€¤: {state['similarity_threshold']})")

    if state["is_unique"]:
        print("âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ†ãƒ¼ãƒã¨åˆ¤å®š")
    else:
        most_similar_idx = int(np.argmax(similarities))
        print(f"âš ï¸  é¡ä¼¼ãƒ†ãƒ¼ãƒæ¤œå‡º: '{state['existing_themes'][most_similar_idx]}' (é¡ä¼¼åº¦: {max_similarity:.4f})")

    return state


def should_regenerate(state: ThemeGenerationState) -> str:
    """å†ç”ŸæˆãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if state["is_unique"]:
        return "unique"
    elif state["attempt_count"] >= state["max_attempts"]:
        print(f"âš ï¸  æœ€å¤§è©¦è¡Œå›æ•° ({state['max_attempts']}) ã«é”ã—ã¾ã—ãŸ")
        return "max_attempts"
    else:
        return "regenerate"


def finalize(state: ThemeGenerationState) -> ThemeGenerationState:
    """æœ€çµ‚å‡¦ç†"""
    if state["is_unique"]:
        print(f"\nğŸ‰ ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ†ãƒ¼ãƒãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ: '{state['candidate_theme']}'")
    else:
        print(f"\nâš ï¸  å®Œå…¨ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ†ãƒ¼ãƒã¯ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸãŒã€æœ€å–„ã®å€™è£œ: '{state['candidate_theme']}'")
    return state


# LangGraphã®æ§‹ç¯‰
def create_theme_generator_graph():
    """ãƒ†ãƒ¼ãƒç”Ÿæˆã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    workflow = StateGraph(ThemeGenerationState)

    # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
    workflow.add_node("fetch_themes", fetch_existing_themes)
    workflow.add_node("generate", generate_theme)
    workflow.add_node("check_similarity", check_similarity)
    workflow.add_node("finalize", finalize)

    # ã‚¨ãƒƒã‚¸ã®å®šç¾©
    workflow.set_entry_point("fetch_themes")
    workflow.add_edge("fetch_themes", "generate")
    workflow.add_edge("generate", "check_similarity")

    # æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸
    workflow.add_conditional_edges(
        "check_similarity",
        should_regenerate,
        {
            "unique": "finalize",
            "max_attempts": "finalize",
            "regenerate": "generate"
        }
    )

    workflow.add_edge("finalize", END)

    return workflow.compile()


def generate_unique_theme(
    category: str = "ä¸€èˆ¬",
    similarity_threshold: float = 0.7,
    max_attempts: int = 5,
    db_path: str = "themes.db",
    save_to_db: bool = False
) -> dict:
    """
    ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ†ãƒ¼ãƒã‚’ç”Ÿæˆ

    Args:
        category: ãƒ†ãƒ¼ãƒã®ã‚«ãƒ†ã‚´ãƒª
        similarity_threshold: é¡ä¼¼åº¦ã®é–¾å€¤ï¼ˆã“ã®å€¤æœªæº€ãªã‚‰ãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼‰
        max_attempts: æœ€å¤§è©¦è¡Œå›æ•°
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¹
        save_to_db: ç”Ÿæˆã—ãŸãƒ†ãƒ¼ãƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã‹

    Returns:
        ç”Ÿæˆçµæœã®è¾æ›¸
    """
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
    init_database(db_path)

    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    app = create_theme_generator_graph()

    # åˆæœŸçŠ¶æ…‹
    initial_state = {
        "existing_themes": [],
        "candidate_theme": "",
        "is_unique": False,
        "attempt_count": 0,
        "max_attempts": max_attempts,
        "similarity_threshold": similarity_threshold,
        "max_similarity": 0.0,
        "db_path": db_path,
        "category": category
    }

    # ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œ
    result = app.invoke(initial_state)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    if save_to_db and result["candidate_theme"]:
        theme_id = add_theme_to_db(result["candidate_theme"], db_path)
        print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ (ID: {theme_id})")

    return {
        "theme": result["candidate_theme"],
        "is_unique": result["is_unique"],
        "max_similarity": result["max_similarity"],
        "attempts": result["attempt_count"]
    }


if __name__ == "__main__":
    # ä½¿ç”¨ä¾‹
    print("=" * 60)
    print("LangGraph ãƒ†ãƒ¼ãƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ¼ãƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ï¼ˆåˆå›ã®ã¿ï¼‰
    init_database()
    existing_themes = get_all_themes()

    if len(existing_themes) == 0:
        print("\nğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ¼ãƒã‚’è¿½åŠ ã—ã¾ã™...")
        sample_themes = [
            "æœªæ¥ã®éƒ½å¸‚ç”Ÿæ´»",
            "å®‡å®™æ¢æ¤œã®å†’é™º",
            "AI ã¨äººé–“ã®å…±ç”Ÿ",
            "æŒç¶šå¯èƒ½ãªç¤¾ä¼š",
            "ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¢ãƒ¼ãƒˆã®é©æ–°"
        ]
        for theme in sample_themes:
            add_theme_to_db(theme)
        print(f"âœ… {len(sample_themes)}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ†ãƒ¼ãƒã‚’è¿½åŠ ã—ã¾ã—ãŸ")

    # æ–°ã—ã„ãƒ†ãƒ¼ãƒã‚’ç”Ÿæˆ
    print("\n" + "=" * 60)
    result = generate_unique_theme(
        category="ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã¨ç¤¾ä¼š",
        similarity_threshold=0.7,
        max_attempts=5,
        save_to_db=True
    )

    print("\n" + "=" * 60)
    print("ğŸ“‹ ç”Ÿæˆçµæœ:")
    print(f"  ãƒ†ãƒ¼ãƒ: {result['theme']}")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯: {result['is_unique']}")
    print(f"  æœ€å¤§é¡ä¼¼åº¦: {result['max_similarity']:.4f}")
    print(f"  è©¦è¡Œå›æ•°: {result['attempts']}")
    print("=" * 60)
